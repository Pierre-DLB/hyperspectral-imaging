{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto encoder based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from typing import Dict, List\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import utils as u\n",
    "import RPNetRFextractor as rp\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "configuration = yaml.safe_load(open('config.yaml'))\n",
    "data_path= configuration[\"data\"]\n",
    "parameters = configuration[\"parameters\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Auto-encoders\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,n_in: int,\n",
    "                  n_out: int,\n",
    "                  n_hidden: List[int] ):\n",
    "        \n",
    "        super.__init__()\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        self.n_hidden= n_hidden\n",
    "\n",
    "        in_list= [n_in] + n_hidden\n",
    "        out_list= n_hidden + n_out\n",
    "\n",
    "        self.encoder= nn.Sequential(\n",
    "            *[nn.Sequential(nn.Linear(x, y), nn.ReLU()) for x,y in zip(in_list, out_list)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,n_in: int,\n",
    "                  n_out: int,\n",
    "                  n_hidden: List[int]):\n",
    "        super.__init__(self)\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        self.n_hidden= n_hidden\n",
    "\n",
    "        in_list= [n_in] + n_hidden\n",
    "        out_list= n_hidden + n_out\n",
    "\n",
    "        self.decoder= nn.Sequential(\n",
    "            *[nn.Sequential(nn.ReLU(), nn.Linear(x, y)) for x,y in zip(in_list, out_list)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.decoder(x)\n",
    "    \n",
    "class AE(nn.Module):\n",
    "    def __init__(self, n_in: int, \n",
    "                 bottleneck: int, \n",
    "                 n_hidden_encoder: List[int], \n",
    "                 n_hidden_decoder: List[int] = None):\n",
    "        super.__init__(self)\n",
    "        self.n_in = n_in\n",
    "        self.n_hidden_encoder=n_hidden_encoder\n",
    "        self.bottleneck = bottleneck\n",
    "        if n_hidden_decoder is None:\n",
    "            # basecase : symetrical\n",
    "            self.n_hidden_decoder= n_hidden_encoder[::-1]\n",
    "        else:\n",
    "            self.n_hidden_decoder= n_hidden_decoder\n",
    "\n",
    "        self.encoder = Encoder(n_in, bottleneck, n_hidden_encoder)\n",
    "        self.decoder = Decoder(bottleneck, n_in, self.n_hidden_decoder)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return(self.encoder(self.encoder(x)))\n",
    "    \n",
    "    def encode(self, x: torch.Tensor):\n",
    "        return(self.encoder(x))\n",
    "    \n",
    "    def decode(self, y: torch.Tensor):\n",
    "        return(self.decode(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=15, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=15, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Sequential(*[nn.Linear(10, 15), nn.ReLU(), nn.Linear(15, 17)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tesing the 1D CNN approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D CNN approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "headmind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
